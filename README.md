---
title: Twitter Bot News
emoji: ðŸ¤–
colorFrom: blue
colorTo: indigo
sdk: docker
pinned: false
---

# Serveur MCP Twitter Bot News

Ce projet implÃ©mente un serveur MCP (Model Context Protocol) en Python, fournissant des outils pour un bot Twitter automatisÃ©, notamment un scraper web, une recherche web et la publication de tweets.

## PrÃ©requis

- Python 3.10+
- `uv` (recommandÃ©) ou `pip`
- Compte Twitter Developer (pour la publication de tweets)

## Installation

1.  CrÃ©er un environnement virtuel :
    ```bash
    python -m venv .venv
    source .venv/bin/activate  # Sur Windows: .venv\Scripts\activate
    ```

2.  Installer les dÃ©pendances :
    ```bash
    pip install -r requirements.txt
    ```

3.  Installer les navigateurs Playwright :
    ```bash
    playwright install chromium
    ```

4.  Configurer les credentials Twitter (optionnel) :
    ```bash
    cp .env.example .env
    # Ã‰diter .env avec vos credentials Twitter
    ```

## Configuration Twitter

Pour utiliser la fonctionnalitÃ© de publication de tweets, vous devez obtenir des credentials d'API Twitter :

1. CrÃ©ez un compte dÃ©veloppeur sur [Twitter Developer Portal](https://developer.twitter.com/)
2. CrÃ©ez une application et gÃ©nÃ©rez vos clÃ©s API
3. Ajoutez les credentials dans le fichier `.env` :
   ```
   TWITTER_API_KEY=votre_api_key
   TWITTER_API_SECRET=votre_api_secret
   TWITTER_ACCESS_TOKEN=votre_access_token
   TWITTER_ACCESS_TOKEN_SECRET=votre_access_token_secret
   ```

## Utilisation

### Lancer le serveur MCP

Le serveur utilise `fastmcp` et communique via stdio.

```bash
python server.py
```

### Tester le scraper

Un script de test est fourni pour vÃ©rifier le fonctionnement de Playwright indÃ©pendamment de MCP :

```bash
python test_scraper.py
```

### Interface de test Streamlit

Une interface web Streamlit est disponible pour tester l'outil de scraping :

```bash
streamlit run interface.py
```

## Outils Disponibles

Le serveur MCP expose les outils suivants :

### `scrape(url: str) -> str`
Scrape le contenu textuel d'une page web en utilisant Playwright.
- **ParamÃ¨tres** : `url` - L'URL de la page Ã  scraper
- **Retour** : Le titre et le contenu textuel de la page

### `search_web(query: str, max_results: int = 5) -> str`
Effectue une recherche web via DuckDuckGo et retourne les rÃ©sultats.
- **ParamÃ¨tres** : 
  - `query` - La requÃªte de recherche
  - `max_results` - Nombre maximum de rÃ©sultats (dÃ©faut: 5)
- **Retour** : Liste formatÃ©e des rÃ©sultats avec titres, URLs et descriptions

### `post_tweet(content: str) -> str`
Publie un tweet sur le compte Twitter configurÃ©.
- **ParamÃ¨tres** : `content` - Le contenu du tweet (max 280 caractÃ¨res)
- **Retour** : L'ID du tweet publiÃ© ou un message d'erreur
- **Note** : NÃ©cessite la configuration des credentials dans `.env`

## Architecture

```
Bot-Twitter-news/
â”œâ”€â”€ server.py           # Serveur MCP principal
â”œâ”€â”€ interface.py        # Interface Streamlit de test
â”œâ”€â”€ test_scraper.py     # Script de test du scraper
â”œâ”€â”€ requirements.txt    # DÃ©pendances Python
â”œâ”€â”€ .env.example        # Template de configuration
â””â”€â”€ tools/              # Modules d'outils
    â”œâ”€â”€ scraper.py      # Outil de scraping Playwright
    â”œâ”€â”€ search.py       # Outil de recherche web
    â””â”€â”€ twitter.py      # Outil de publication Twitter
```

## Prochaines Ã©tapes

- [ ] Planification automatique de tweets
- [ ] GÃ©nÃ©ration de contenu avec IA
- [ ] SystÃ¨me de veille automatique sur des sujets

